# import torch_xla.core.xla_model as xm
# def is_tpu_available():
#     return xm.xla_device() != None
# print(is_tpu_available())